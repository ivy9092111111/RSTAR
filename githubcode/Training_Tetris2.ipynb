{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dc781fd-5bf3-4c98-ac2d-1b986279013c",
   "metadata": {},
   "source": [
    "## Code for \"RSTAR4D: Rotational Streak Artifact Reduction in 4D CBCT Using Separable 4D Convolutions\", published in IEEE TRPMS\n",
    "\n",
    "Authors:Ziheng Deng, Jun Zhao, SJTU\n",
    "\n",
    "The RSTAR4D-Net is a 4D CNN with separable 4D Convolutions. To effectively train the model with limited 4D data, we propose the Tetris training strategy. \n",
    "\n",
    "Here is the Tetris training stage 2. After training on 2D+T data, in this stage, we train the pre-trained model on 4D data. As we do not have enough 4D data, we crop the 4D data into 4D blocks/patches with hybrid image size. Specifically, The input and output data size can be 1\\*2\\*10\\*16\\*256\\*256, 1\\*2\\*10\\*32\\*144\\*144, or 1\\*2\\*10\\*64\\*128\\*128, (batch, channel, phase(temporal), slice (z-axis, SI), width (y-axis, LR), height(x-axis AP)), please check the example_data. In this stage, the z-axis (SI) convolution is activated. \n",
    "\n",
    "After Tetris training stage 2, the model can be directly used for 1\\*2\\*10\\*96\\*256\\*256 real 4D CBCT data using an RTX 3090 with 24GB memory. Pretrained model is provided in checkpoints/checkpoints_Tetris2.pth\n",
    "\n",
    "Note when transfer the pre-trained model to 4D data, we need to first properly initialize the parameters of the z-axis convolutional layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670eaf4-c371-4f70-98cb-8a136f06308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim, autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.utils.spectral_norm as spectral_norm\n",
    "import torchvision\n",
    "from math import exp\n",
    "from pytorch_msssim import ms_ssim,ssim\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744bf36-9322-41ab-83a4-932e154acc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69271860-7a96-4ea0-acb5-f8d67653a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simudata(Dataset):\n",
    "    def __init__(self,simu_dir,transform=None):\n",
    "        self.simu_dir = simu_dir\n",
    "        self.transform = transform\n",
    "        self.simu = os.listdir(self.simu_dir)\n",
    "        self.simu.sort()  \n",
    "    def __len__(self):\n",
    "        return len(self.simu)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        simu_index = self.simu[index]\n",
    "        simu_path = os.path.join(self.simu_dir,simu_index)\n",
    "        \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('cbct') \n",
    "            cbct=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "            \n",
    "            \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('ct') \n",
    "            ct=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "        \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('prior') \n",
    "            prior=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "                \n",
    "        cbct=cbct.float().unsqueeze(0)/1000\n",
    "        ct=ct.float().unsqueeze(0)/1000\n",
    "        prior=prior.float().unsqueeze(0)/1000\n",
    "        \n",
    "        return cbct,ct,prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0fa0a0-f9d2-4108-84fb-cf43170ec941",
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaldata(Dataset):\n",
    "    def __init__(self,simu_dir,transform=None):\n",
    "        self.simu_dir = simu_dir\n",
    "        self.transform = transform\n",
    "        self.simu = os.listdir(self.simu_dir)\n",
    "        self.simu.sort()  \n",
    "    def __len__(self):\n",
    "        return len(self.simu)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        simu_index = self.simu[index]\n",
    "        simu_path = os.path.join(self.simu_dir,simu_index)\n",
    "            \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('cbct') \n",
    "            cbct4=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "   \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('ct') \n",
    "            ct=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "        \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('prior') \n",
    "            prior=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "                \n",
    "        cbct4=cbct4.float().unsqueeze(0)/1000\n",
    "        ct=ct.float().unsqueeze(0)/1000\n",
    "        prior=prior.float().unsqueeze(0)/1000\n",
    "        \n",
    "        return cbct4,ct,prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a539eb6-30eb-45b3-84a5-6f331b67a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "simudataset = simudata('example_data/train_data_stage2')\n",
    "evaldataset = evaldata('example_data/eval_data_stage2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a945481-0ff3-45b0-bd3a-57af89eb9b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderX(DataLoader):\n",
    "\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7c1d6-cae8-4fb9-a4bd-0e59f0304d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "simuloader = DataLoaderX(simudataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "evalloader = DataLoaderX(evaldataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773db2b6-706d-4f10-8f6d-5fe548165e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convwithactivation(nn.Module):\n",
    "    # Spatial downsampling layer\n",
    "    def __init__(self,in_ch,out_ch,kernel_size=[3,3,3],padding=[1,1,1],stride=[1,1,1],padding_mode='zeros'):\n",
    "        super(convwithactivation,self).__init__()\n",
    "        # XY downsamapling\n",
    "        self.conv1=nn.Conv3d(in_ch,out_ch,[1,kernel_size[1],kernel_size[2]],[1,stride[1],stride[2]],[0,padding[1],padding[2]],padding_mode=padding_mode)\n",
    "        # Z downsampling\n",
    "        self.conv2=nn.Conv3d(out_ch,out_ch,[1,kernel_size[0],1],[1,stride[0],1],[0,padding[0],0],padding_mode='replicate')\n",
    "        self.lrelu=nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.stride=stride\n",
    "        self.out_ch=out_ch\n",
    "        \n",
    "    def forward(self,x):\n",
    "        [B,C,T,Z,Y,X]=x.shape\n",
    "        x = x.view(B,C,T*Z,Y,X)\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(B,self.out_ch,T,Z,-1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = x.view(B,self.out_ch,T,Z//self.stride[0],Y//self.stride[1],X//self.stride[2])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228fe840-236d-4b57-9bb0-581f681bd8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convwithactivation4DRSTAR(nn.Module):\n",
    "    # separable 4D convolution\n",
    "    def __init__(self,in_ch,out_ch,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1],ifrelu=1):\n",
    "        super(convwithactivation4DRSTAR,self).__init__()\n",
    "        # XY conv，TZ*Y*X\n",
    "        self.conv1=nn.Conv3d(int(1*in_ch),int(1*out_ch),[1,kernel_size[2],kernel_size[3]],[1,stride[2],stride[3]],[0,padding[2],padding[3]])\n",
    "        # Z conv，T*Z*YX\n",
    "        self.conv2=nn.Conv3d(int(1*in_ch),int(1*out_ch),[1,kernel_size[1],1],[1,stride[1],1],[0,padding[1],0],padding_mode='replicate')\n",
    "        # T conv，T*Z*YX\n",
    "        self.conv3=nn.Conv3d(int(1*in_ch),int(1*out_ch),[kernel_size[0],1,1],[stride[0],1,1],[padding[0],0,0],padding_mode='circular')\n",
    "\n",
    "        # XY conv，TZ*Y*X\n",
    "        self.conv1_2=nn.Conv3d(int(1*out_ch),int(1*out_ch),[1,kernel_size[2],kernel_size[3]],[1,stride[2],stride[3]],[0,padding[2],padding[3]])\n",
    "        # Z conv，T*Z*YX\n",
    "        self.conv2_2=nn.Conv3d(int(1*out_ch),int(1*out_ch),[1,kernel_size[1],1],[1,stride[1],1],[0,padding[1],0],padding_mode='replicate')\n",
    "        # T conv，T*Z*YX\n",
    "        self.conv3_2=nn.Conv3d(int(1*out_ch),int(1*out_ch),[kernel_size[0],1,1],[stride[0],1,1],[padding[0],0,0],padding_mode='circular')\n",
    "\n",
    "        self.lrelu1=nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.in_ch=in_ch\n",
    "        self.out_ch=out_ch\n",
    "        self.ifrelu=ifrelu\n",
    "        \n",
    "    def forward(self,x):\n",
    "        [B,C,T,Z,Y,X]=x.shape\n",
    "        x = self.conv1(x.view(B,C,T*Z,Y,X)).view(B,self.out_ch,T,Z,-1)+self.conv2(x.view(B,C,T,Z,-1))+self.conv3(x.view(B,C,T,Z,-1))\n",
    "        x = self.conv1_2(x.view(B,self.out_ch,T*Z,Y,X)).view(B,self.out_ch,T,Z,-1)+self.conv2_2(x)+self.conv3_2(x)\n",
    "\n",
    "        if(self.ifrelu==1):\n",
    "            x = self.lrelu1(x)\n",
    "        x = x.view(B,self.out_ch,T,Z,Y,X)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7679a7-6b97-4023-b0e4-eeeef197eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class upconvwithactivation(nn.Module):\n",
    "    # Spatial upsampling\n",
    "    def __init__(self,in_ch,out_ch,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1],scale_factor=[1,2,2,2],ifrelu=1):\n",
    "        super(upconvwithactivation,self).__init__()\n",
    "        self.scale_factor=scale_factor\n",
    "        self.conv=convwithactivation4DRSTAR(in_ch,out_ch,kernel_size,padding,stride,ifrelu)\n",
    "    def forward(self,x):\n",
    "        [B,C,T,Z,Y,X]=x.shape\n",
    "        x = x.view(B,C*T,Z,Y,X)\n",
    "        x = F.interpolate(x,scale_factor=self.scale_factor[1:],mode='nearest')\n",
    "        x = x.view(B,C,T,Z*self.scale_factor[1],Y*self.scale_factor[2],X*self.scale_factor[3])\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a44875-8407-47d1-a076-4d6ff99667eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myUNet,self).__init__()\n",
    "        cnum=16\n",
    "        self.conv1=convwithactivation(2,cnum,kernel_size=[3,3,3],padding=[1,1,1],stride=[2,1,1],padding_mode='zeros')\n",
    "        self.conv1_2=convwithactivation4DRSTAR(cnum,cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv1_3=convwithactivation4DRSTAR(cnum,cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "\n",
    "        self.conv2=convwithactivation(cnum,2*cnum,kernel_size=[3,3,3],padding=[1,1,1],stride=[1,2,2],padding_mode='zeros')\n",
    "        self.conv2_2=convwithactivation4DRSTAR(2*cnum,2*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv2_3=convwithactivation4DRSTAR(2*cnum,2*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv3=convwithactivation(2*cnum,4*cnum,kernel_size=[3,3,3],padding=[1,1,1],stride=[1,2,2],padding_mode='zeros')\n",
    "        self.conv3_2=convwithactivation4DRSTAR(4*cnum,4*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv3_3=convwithactivation4DRSTAR(4*cnum,4*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv4=convwithactivation(4*cnum,8*cnum,kernel_size=[3,3,3],padding=[1,1,1],stride=[1,2,2],padding_mode='zeros')\n",
    "        self.conv4_2=convwithactivation4DRSTAR(8*cnum,8*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv4_3=convwithactivation4DRSTAR(8*cnum,8*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv5=upconvwithactivation(8*cnum,4*cnum,kernel_size=[3,3,3,3],stride=[1,1,1,1],padding=[1,1,1,1],scale_factor=[1,1,2,2])\n",
    "        self.conv5_2=convwithactivation4DRSTAR(8*cnum,4*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv5_3=convwithactivation4DRSTAR(4*cnum,4*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv6=upconvwithactivation(4*cnum,2*cnum,kernel_size=[3,3,3,3],stride=[1,1,1,1],padding=[1,1,1,1],scale_factor=[1,1,2,2])\n",
    "        self.conv6_2=convwithactivation4DRSTAR(4*cnum,2*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv6_3=convwithactivation4DRSTAR(2*cnum,2*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv7=upconvwithactivation(2*cnum,1*cnum,kernel_size=[3,3,3,3],stride=[1,1,1,1],padding=[1,1,1,1],scale_factor=[1,1,2,2])\n",
    "        self.conv7_2=convwithactivation4DRSTAR(2*cnum,1*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv7_3=convwithactivation4DRSTAR(1*cnum,1*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        ##output\n",
    "        self.conv8=upconvwithactivation(1*cnum,1,kernel_size=[3,3,3,3],stride=[1,1,1,1],padding=[1,1,1,1],scale_factor=[1,2,1,1],ifrelu=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv1_3(self.conv1_2(x))+x\n",
    "        x1=self.conv2(x)\n",
    "        x1=self.conv2_3(self.conv2_2(x1))+x1\n",
    "        x2=self.conv3(x1)\n",
    "        x2=self.conv3_3(self.conv3_2(x2))+x2\n",
    "        x3=self.conv4(x2)\n",
    "        x3=self.conv4_3(self.conv4_2(x3))+x3\n",
    "        \n",
    "        x3=self.conv5(x3)\n",
    "        x3=self.conv5_3(self.conv5_2(torch.cat([x3,x2],dim=1)))+x3\n",
    "        x3=self.conv6(x3)\n",
    "        x3=self.conv6_3(self.conv6_2(torch.cat([x3,x1],dim=1)))+x3\n",
    "        x3=self.conv7(x3)\n",
    "        x3=self.conv7_3(self.conv7_2(torch.cat([x3,x],dim=1)))+x3\n",
    "        x3=self.conv8(x3)\n",
    "        \n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429d440-9d88-4033-bd8b-43077e76871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=myUNet().to(DEVICE)\n",
    "params = list(model.parameters())\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "scaler=GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413d2cb-974e-44f2-bff5-31a749915c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(model,device,trainloader,optimizer,epoch):\n",
    "    start=time.time()\n",
    "    loss_sim_sum=0\n",
    "    loss_ssim_sum=0\n",
    "    model.train()\n",
    "    for batch_idx,(cbct,ct,prior) in enumerate(trainloader):\n",
    "        ct=ct.to(device)\n",
    "        cbct=cbct.to(device)\n",
    "        prior=prior.to(device)\n",
    "        with autocast():\n",
    "            cbct_refine=model(torch.cat([cbct,prior.unsqueeze(2).expand_as(cbct)],dim=1))\n",
    "            loss_sim=loss_fn(cbct_refine.squeeze(1),ct.squeeze(1))\n",
    "        loss_ssim=ssim(cbct_refine.squeeze(1).float()*1000,ct.squeeze(1)*1000)\n",
    "        with autocast():\n",
    "            loss_G=loss_sim+(1-loss_ssim)*0.1\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss_G).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        #loss_G.backward()\n",
    "        #optimizer.step()\n",
    "        \n",
    "        loss_sim_sum += loss_sim.cpu().item()\n",
    "        loss_ssim_sum += loss_ssim.cpu().item()\n",
    "        \n",
    "        if(batch_idx+1)%3==0:\n",
    "            print('Train Epoch: %d, loss_sim %.4f, loss_ssim %.4f, time %.1f sec' % (epoch,loss_sim_sum*4/36,loss_ssim_sum*4/36,time.time()-start))\n",
    "            loss_sim_sum=0\n",
    "            loss_ssim_sum=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868f2cb-1ca0-483c-b267-b6224952f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval1(model,device,trainloader,epoch):\n",
    "    start=time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_sim_sum=0\n",
    "        loss_ssim_sum=0\n",
    "        for batch_idx,(cbct,ct,prior) in enumerate(trainloader):\n",
    "            cbct=cbct.to(device)\n",
    "            ct=ct.to(device)\n",
    "            prior=prior.to(device)\n",
    "            with autocast():\n",
    "                cbct_refine=model(torch.cat([cbct,prior.unsqueeze(2).expand_as(cbct)],dim=1))\n",
    "                loss_sim=loss_fn(cbct_refine,ct)\n",
    "            loss_ssim=ssim(cbct_refine.float().squeeze(1)*1000,ct.squeeze(1)*1000)\n",
    "            loss_sim_sum += loss_sim.cpu().item()\n",
    "            loss_ssim_sum += loss_ssim.cpu().item()\n",
    "        print('eval Epoch: %d, loss_sim %.4f, loss_ssim %.4f' % (epoch,loss_sim_sum*90,loss_ssim_sum/(batch_idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517e315-8ab0-4d93-8f61-2f604b9f5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading Tetris Stage 1 checkpoints\n",
    "w_path=torch.load('checkpoints/checkpoints_Tetris1.pth',map_location='cuda:0')\n",
    "model.load_state_dict(w_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b63c30c-fea3-43c1-b0c9-1ab7d70f8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the z-axis convolution\n",
    "\n",
    "nn.init.dirac_(model.conv1.conv2.weight)\n",
    "nn.init.zeros_(model.conv1_2.conv2.weight)\n",
    "nn.init.zeros_(model.conv1_2.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv1_3.conv2.weight)\n",
    "nn.init.zeros_(model.conv1_3.conv2_2.weight)\n",
    "nn.init.dirac_(model.conv2.conv2.weight)\n",
    "nn.init.zeros_(model.conv2_2.conv2.weight)\n",
    "nn.init.zeros_(model.conv2_2.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv2_3.conv2.weight)\n",
    "nn.init.zeros_(model.conv2_3.conv2_2.weight)\n",
    "nn.init.dirac_(model.conv3.conv2.weight)\n",
    "nn.init.zeros_(model.conv3_2.conv2.weight)\n",
    "nn.init.zeros_(model.conv3_2.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv3_3.conv2.weight)\n",
    "nn.init.zeros_(model.conv3_3.conv2_2.weight)\n",
    "nn.init.dirac_(model.conv4.conv2.weight)\n",
    "nn.init.zeros_(model.conv4_2.conv2.weight)\n",
    "nn.init.zeros_(model.conv4_2.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv4_3.conv2.weight)\n",
    "nn.init.zeros_(model.conv4_3.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv5.conv.conv2.weight)\n",
    "nn.init.zeros_(model.conv5.conv.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv5_2.conv2.weight)\n",
    "nn.init.zeros_(model.conv5_2.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv5_3.conv2.weight)\n",
    "nn.init.zeros_(model.conv5_3.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv6.conv.conv2.weight)\n",
    "nn.init.zeros_(model.conv6.conv.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv6_2.conv2.weight)\n",
    "nn.init.zeros_(model.conv6_2.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv6_3.conv2.weight)\n",
    "nn.init.zeros_(model.conv6_3.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv7.conv.conv2.weight)\n",
    "nn.init.zeros_(model.conv7.conv.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv7_2.conv2.weight)\n",
    "nn.init.zeros_(model.conv7_2.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv7_3.conv2.weight)\n",
    "nn.init.zeros_(model.conv7_3.conv2_2.weight)\n",
    "nn.init.zeros_(model.conv8.conv.conv2.weight)\n",
    "nn.init.zeros_(model.conv8.conv.conv2_2.weight)\n",
    "               \n",
    "nn.init.zeros_(model.conv1.conv2.bias)\n",
    "nn.init.zeros_(model.conv1_2.conv2.bias)\n",
    "nn.init.zeros_(model.conv1_2.conv2_2.bias)               \n",
    "nn.init.zeros_(model.conv1_3.conv2.bias)\n",
    "nn.init.zeros_(model.conv1_3.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv2.conv2.bias)\n",
    "nn.init.zeros_(model.conv2_2.conv2.bias)\n",
    "nn.init.zeros_(model.conv2_2.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv2_3.conv2.bias)\n",
    "nn.init.zeros_(model.conv2_3.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv3.conv2.bias)\n",
    "nn.init.zeros_(model.conv3_2.conv2.bias)\n",
    "nn.init.zeros_(model.conv3_2.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv3_3.conv2.bias)\n",
    "nn.init.zeros_(model.conv3_3.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv4.conv2.bias)\n",
    "nn.init.zeros_(model.conv4_2.conv2.bias)\n",
    "nn.init.zeros_(model.conv4_2.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv4_3.conv2.bias)\n",
    "nn.init.zeros_(model.conv4_3.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv5.conv.conv2.bias)\n",
    "nn.init.zeros_(model.conv5.conv.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv5_2.conv2.bias)\n",
    "nn.init.zeros_(model.conv5_2.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv5_3.conv2.bias)\n",
    "nn.init.zeros_(model.conv5_3.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv6.conv.conv2.bias)\n",
    "nn.init.zeros_(model.conv6.conv.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv6_2.conv2.bias)\n",
    "nn.init.zeros_(model.conv6_2.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv6_3.conv2.bias)\n",
    "nn.init.zeros_(model.conv6_3.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv7.conv.conv2.bias)\n",
    "nn.init.zeros_(model.conv7.conv.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv7_2.conv2.bias)\n",
    "nn.init.zeros_(model.conv7_2.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv7_3.conv2.bias)\n",
    "nn.init.zeros_(model.conv7_3.conv2_2.bias)\n",
    "nn.init.zeros_(model.conv8.conv.conv2.bias)\n",
    "nn.init.zeros_(model.conv8.conv.conv2_2.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb949b0-fee7-4331-92fc-db8d670ddbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## see if the initialization works\n",
    "eval1(model,DEVICE,evalloader,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88a02f-c857-4b6e-a814-9e38a43c9d8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lrate=0.00015\n",
    "optimizer=torch.optim.Adam(params,lr=lrate,betas=(0.9, 0.999))\n",
    "for epoch in range(1,31):\n",
    "    train1(model,DEVICE,simuloader,optimizer,epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "    #torch.save(model.state_dict(),'checkpoints/checkpoints_Tetris2/model_%s.pth'%(epoch))\n",
    "    if (epoch==10 or epoch==20 or epoch==25):\n",
    "        lrate=lrate*0.5\n",
    "        for params in optimizer.param_groups:             \n",
    "            params['lr'] = lrate \n",
    "    eval1(model,DEVICE,evalloader,epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31051580-fe3e-4f64-8820-8b2b0e882790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049abe0d-295b-4876-8569-f4a0fa12d6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd238a-cc6a-424a-8886-e3afb4bc545a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada95002-b67e-43a7-9d05-dd9b6fa5993e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6a525-6969-4063-a914-75291abef0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c115ac6-3b9a-47a4-b796-7893ac9b4b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e1fc0-1d28-4fcd-8841-6a02769d1787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ff516-7519-4686-85fb-5e2f8eac8126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc55aa-5250-4969-abdc-b3c7f589ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f9e234-f893-4573-bea2-dfc03ec1dc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05469d0c-3e6e-4312-8165-0d0880a7c773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494914db-bb65-41a6-8cd5-9a4cff66dbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb782d4b-a90a-4ac6-9dd3-0bf2604b2a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03b4cb-8a13-4a02-a36d-6ff680d7bb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883c8bb-c2b9-431e-8e78-bf692c5149a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7da47-6b82-467c-953c-aceec6b09076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f3602-0273-4b06-a1e3-c95f88a2ff8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b3598-00e6-43bc-abdb-3781817bc9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899d945-506b-4535-8fae-be117fb61076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82344262-10e1-4de0-bc1a-ec3815ace98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ee859-8793-4f1c-ac72-52a0d7b5dc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3b964-cd10-4d74-8a04-0f19a56df542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2fccb1-57a8-4965-b86b-c808c05133d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc037a8d-5be7-40e0-a2d1-a7daa723df4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596abdc-72fe-4f2b-8534-41ccf779c9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f2b40-a9ee-4cd7-8f5c-3fed8915bf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee20ab-a1d0-428c-914d-2722ad92946b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f798a1-e012-4e5a-8397-c12756a92377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ca7a4-1c72-4e8e-b0db-6cc93c3d030f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
