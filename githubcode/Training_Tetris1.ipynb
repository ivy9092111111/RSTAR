{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38efb87-3691-4ea0-a781-5c1ff6848584",
   "metadata": {},
   "source": [
    "## Code for \"RSTAR4D: Rotational Streak Artifact Reduction in 4D CBCT Using Separable 4D Convolutions\", published in IEEE TRPMS\n",
    "\n",
    "Authors:Ziheng Deng, Jun Zhao, SJTU\n",
    "\n",
    "The RSTAR4D-Net is a 4D CNN with separable 4D Convolutions. To effectively train the model with limited 4D data, we propose the Tetris training strategy. \n",
    "\n",
    "Here is the Tetris training stage 1. We first train the model on 2D+T data. The input and output data size is 1\\*2\\*10\\*1\\*256\\*256 (batch, channel, phase(temporal), slice (z-axis, SI), width (y-axis, LR), height(x-axis AP)), please check the example_data. In this stage, the z-axis (SI) convolution is freezed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99065124-1485-4c31-9944-178dd58453bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim, autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from math import exp\n",
    "from pytorch_msssim import ms_ssim,ssim\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a294d-02a1-4575-86f7-a6597cc33cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4f628-776c-4320-9e0e-1515a0996e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simudata(Dataset):\n",
    "    def __init__(self,simu_dir,transform=None):\n",
    "        self.simu_dir = simu_dir\n",
    "        self.transform = transform\n",
    "        self.simu = os.listdir(self.simu_dir)\n",
    "        self.simu.sort()  \n",
    "    def __len__(self):\n",
    "        return len(self.simu)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        simu_index = self.simu[index]\n",
    "        simu_path = os.path.join(self.simu_dir,simu_index)\n",
    "        \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('cbct') \n",
    "            cbct=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "            \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('ct') \n",
    "            ct=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "        \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('prior') \n",
    "            prior=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "                \n",
    "        cbct=cbct.unsqueeze(1).float().unsqueeze(0)/1000\n",
    "        ct=ct.unsqueeze(1).float().unsqueeze(0)/1000\n",
    "        prior=prior.unsqueeze(0).float().unsqueeze(0)/1000\n",
    "        \n",
    "        return cbct,ct,prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efef44-1cd4-4db4-89db-3d1211cc8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaldata(Dataset):\n",
    "    def __init__(self,simu_dir,transform=None):\n",
    "        self.simu_dir = simu_dir\n",
    "        self.transform = transform\n",
    "        self.simu = os.listdir(self.simu_dir)\n",
    "        self.simu.sort()  \n",
    "    def __len__(self):\n",
    "        return len(self.simu)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        simu_index = self.simu[index]\n",
    "        simu_path = os.path.join(self.simu_dir,simu_index)\n",
    "            \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('cbct') \n",
    "            cbct4=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "   \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('ct') \n",
    "            ct=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "        \n",
    "        with h5py.File(simu_path,'r') as f:\n",
    "            data = f.get('prior') \n",
    "            prior=torch.tensor(np.array(data) ,dtype=float)\n",
    "            f.close()\n",
    "                \n",
    "        cbct4=cbct4.float().unsqueeze(1).unsqueeze(0)/1000\n",
    "        ct=ct.float().unsqueeze(1).unsqueeze(0)/1000\n",
    "        prior=prior.float().unsqueeze(0).unsqueeze(0)/1000\n",
    "        \n",
    "        return cbct4,ct,prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad3171-0d08-4c58-9dd6-0d475f9e8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "simudataset = simudata('example_data/train_data_stage1')\n",
    "evaldataset = evaldata('example_data/eval_data_stage1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64176d-edb8-4ada-861f-a9038241e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderX(DataLoader):\n",
    "\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b4edd-0c0c-4973-abb2-d5ceeb188be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "simuloader = DataLoaderX(simudataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "evalloader = DataLoaderX(evaldataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74fc4f7-1f1c-46b2-8b52-a610b8fb0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convwithactivation(nn.Module):\n",
    "    # Spatial downsampling layer\n",
    "    def __init__(self,in_ch,out_ch,kernel_size=[3,3,3],padding=[1,1,1],stride=[1,1,1],padding_mode='zeros'):\n",
    "        super(convwithactivation,self).__init__()\n",
    "        # XY downsamapling\n",
    "        self.conv1=nn.Conv3d(in_ch,out_ch,[1,kernel_size[1],kernel_size[2]],[1,stride[1],stride[2]],[0,padding[1],padding[2]],padding_mode=padding_mode)\n",
    "        # Z downsampling\n",
    "        self.conv2=nn.Conv3d(out_ch,out_ch,[1,kernel_size[0],1],[1,stride[0],1],[0,padding[0],0],padding_mode='replicate')\n",
    "        self.lrelu=nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.stride=stride\n",
    "        self.out_ch=out_ch\n",
    "        \n",
    "    def forward(self,x):\n",
    "        [B,C,T,Z,Y,X]=x.shape\n",
    "        x = x.view(B,C,T*Z,Y,X)\n",
    "        x = self.conv1(x)\n",
    "        #x = x.view(B,self.out_ch,T,Z,-1)\n",
    "        #x = self.conv2(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = x.view(B,self.out_ch,T,Z//self.stride[0],Y//self.stride[1],X//self.stride[2])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cbc174-c263-47b7-bf65-150941bce339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convwithactivation4DRSTAR(nn.Module):\n",
    "    # separable 4D convolution\n",
    "    def __init__(self,in_ch,out_ch,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1],ifrelu=1):\n",
    "        super(convwithactivation4DRSTAR,self).__init__()\n",
    "        # XY conv，TZ*Y*X\n",
    "        self.conv1=nn.Conv3d(int(1*in_ch),int(1*out_ch),[1,kernel_size[2],kernel_size[3]],[1,stride[2],stride[3]],[0,padding[2],padding[3]])\n",
    "        # Z conv，T*Z*YX\n",
    "        self.conv2=nn.Conv3d(int(1*in_ch),int(1*out_ch),[1,kernel_size[1],1],[1,stride[1],1],[0,padding[1],0],padding_mode='replicate')\n",
    "        # T conv，T*Z*YX\n",
    "        self.conv3=nn.Conv3d(int(1*in_ch),int(1*out_ch),[kernel_size[0],1,1],[stride[0],1,1],[padding[0],0,0],padding_mode='circular')\n",
    "\n",
    "        # XY conv，TZ*Y*X\n",
    "        self.conv1_2=nn.Conv3d(int(1*out_ch),int(1*out_ch),[1,kernel_size[2],kernel_size[3]],[1,stride[2],stride[3]],[0,padding[2],padding[3]])\n",
    "        # Z conv，T*Z*YX\n",
    "        self.conv2_2=nn.Conv3d(int(1*out_ch),int(1*out_ch),[1,kernel_size[1],1],[1,stride[1],1],[0,padding[1],0],padding_mode='replicate')\n",
    "        # T conv，T*Z*YX\n",
    "        self.conv3_2=nn.Conv3d(int(1*out_ch),int(1*out_ch),[kernel_size[0],1,1],[stride[0],1,1],[padding[0],0,0],padding_mode='circular')\n",
    "\n",
    "        self.lrelu1=nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.in_ch=in_ch\n",
    "        self.out_ch=out_ch\n",
    "        self.ifrelu=ifrelu\n",
    "        \n",
    "    def forward(self,x):\n",
    "        [B,C,T,Z,Y,X]=x.shape\n",
    "        x = self.conv1(x.view(B,C,T*Z,Y,X)).view(B,self.out_ch,T,Z,-1)+self.conv3(x.view(B,C,T,Z,-1))\n",
    "        x = self.conv1_2(x.view(B,self.out_ch,T*Z,Y,X)).view(B,self.out_ch,T,Z,-1)+self.conv3_2(x)\n",
    "\n",
    "        #x = self.conv1(x.view(B,C,T*Z,Y,X)).view(B,self.out_ch,T,Z,-1)+self.conv2(x.view(B,C,T,Z,-1))+self.conv3(x.view(B,C,T,Z,-1))\n",
    "        #x = self.conv1_2(x.view(B,self.out_ch,T*Z,Y,X)).view(B,self.out_ch,T,Z,-1)+self.conv2_2(x)+self.conv3_2(x)\n",
    "\n",
    "        if(self.ifrelu==1):\n",
    "            x = self.lrelu1(x)\n",
    "        x = x.view(B,self.out_ch,T,Z,Y,X)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b817d67-8cdd-4a85-bfd2-d18be92a4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class upconvwithactivation(nn.Module):\n",
    "    # Spatial upsampling\n",
    "    def __init__(self,in_ch,out_ch,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1],scale_factor=[1,2,2,2],ifrelu=1):\n",
    "        super(upconvwithactivation,self).__init__()\n",
    "        self.scale_factor=scale_factor\n",
    "        self.conv=convwithactivation4DRSTAR(in_ch,out_ch,kernel_size,padding,stride,ifrelu)\n",
    "    def forward(self,x):\n",
    "        [B,C,T,Z,Y,X]=x.shape\n",
    "        x = x.view(B,C*T,Z,Y,X)\n",
    "        x = F.interpolate(x,scale_factor=self.scale_factor[1:],mode='nearest')\n",
    "        x = x.view(B,C,T,Z*self.scale_factor[1],Y*self.scale_factor[2],X*self.scale_factor[3])\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc48bc3-584a-44ee-9627-19f88acdee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myUNet,self).__init__()\n",
    "        cnum=16\n",
    "        self.conv1=convwithactivation(2,cnum,kernel_size=[3,3,3],padding=[1,1,1],stride=[1,1,1],padding_mode='zeros')\n",
    "        self.conv1_2=convwithactivation4DRSTAR(cnum,cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv1_3=convwithactivation4DRSTAR(cnum,cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "\n",
    "        self.conv2=convwithactivation(cnum,2*cnum,kernel_size=[3,3,3],padding=[1,1,1],stride=[1,2,2],padding_mode='zeros')\n",
    "        self.conv2_2=convwithactivation4DRSTAR(2*cnum,2*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv2_3=convwithactivation4DRSTAR(2*cnum,2*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv3=convwithactivation(2*cnum,4*cnum,kernel_size=[3,3,3],padding=[1,1,1],stride=[1,2,2],padding_mode='zeros')\n",
    "        self.conv3_2=convwithactivation4DRSTAR(4*cnum,4*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv3_3=convwithactivation4DRSTAR(4*cnum,4*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv4=convwithactivation(4*cnum,8*cnum,kernel_size=[3,3,3],padding=[1,1,1],stride=[1,2,2],padding_mode='zeros')\n",
    "        self.conv4_2=convwithactivation4DRSTAR(8*cnum,8*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv4_3=convwithactivation4DRSTAR(8*cnum,8*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv5=upconvwithactivation(8*cnum,4*cnum,kernel_size=[3,3,3,3],stride=[1,1,1,1],padding=[1,1,1,1],scale_factor=[1,1,2,2])\n",
    "        self.conv5_2=convwithactivation4DRSTAR(8*cnum,4*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv5_3=convwithactivation4DRSTAR(4*cnum,4*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv6=upconvwithactivation(4*cnum,2*cnum,kernel_size=[3,3,3,3],stride=[1,1,1,1],padding=[1,1,1,1],scale_factor=[1,1,2,2])\n",
    "        self.conv6_2=convwithactivation4DRSTAR(4*cnum,2*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv6_3=convwithactivation4DRSTAR(2*cnum,2*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        self.conv7=upconvwithactivation(2*cnum,1*cnum,kernel_size=[3,3,3,3],stride=[1,1,1,1],padding=[1,1,1,1],scale_factor=[1,1,2,2])\n",
    "        self.conv7_2=convwithactivation4DRSTAR(2*cnum,1*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        self.conv7_3=convwithactivation4DRSTAR(1*cnum,1*cnum,kernel_size=[3,3,3,3],padding=[1,1,1,1],stride=[1,1,1,1])\n",
    "        \n",
    "        ##output\n",
    "        self.conv8=upconvwithactivation(1*cnum,1,kernel_size=[3,3,3,3],stride=[1,1,1,1],padding=[1,1,1,1],scale_factor=[1,1,1,1],ifrelu=0)\n",
    "        #self.conv8=convwithactivation4DRSTAR(1*cnum,1,kernel_size=[5,3,3,3],padding=[2,1,1,1],stride=[1,1,1,1],ifrelu=0)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv1_3(self.conv1_2(x))+x\n",
    "        x1=self.conv2(x)\n",
    "        x1=self.conv2_3(self.conv2_2(x1))+x1\n",
    "        x2=self.conv3(x1)\n",
    "        x2=self.conv3_3(self.conv3_2(x2))+x2\n",
    "        x3=self.conv4(x2)\n",
    "        x3=self.conv4_3(self.conv4_2(x3))+x3\n",
    "        \n",
    "        x3=self.conv5(x3)\n",
    "        x3=self.conv5_3(self.conv5_2(torch.cat([x3,x2],dim=1)))+x3\n",
    "        x3=self.conv6(x3)\n",
    "        x3=self.conv6_3(self.conv6_2(torch.cat([x3,x1],dim=1)))+x3\n",
    "        x3=self.conv7(x3)\n",
    "        x3=self.conv7_3(self.conv7_2(torch.cat([x3,x],dim=1)))+x3\n",
    "        x3=self.conv8(x3)\n",
    "        \n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17acc43-43fd-4f77-bdd7-e7ce29a22f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=myUNet().to(DEVICE)\n",
    "params = list(model.parameters())\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "scaler=GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45269432-e6ea-489b-a506-472ce26eb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(model,device,trainloader,optimizer,epoch):\n",
    "    start=time.time()\n",
    "    loss_sim_sum=0\n",
    "    loss_ssim_sum=0\n",
    "    model.train()\n",
    "    for batch_idx,(cbct,ct,prior) in enumerate(trainloader):\n",
    "        ct=ct.to(device)\n",
    "        cbct=cbct.to(device)\n",
    "        prior=prior.to(device)\n",
    "        with autocast():\n",
    "            cbct_refine=model(torch.cat([cbct,prior.unsqueeze(2).expand_as(cbct)],dim=1))\n",
    "            loss_sim=loss_fn(cbct_refine.squeeze(1),ct.squeeze(1))\n",
    "        loss_ssim=ssim(cbct_refine.float()*1000,ct*1000)\n",
    "        with autocast():\n",
    "            loss_G=loss_sim+(1-loss_ssim)*0.1\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss_G).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        #loss_G.backward()\n",
    "        #optimizer.step()\n",
    "        \n",
    "        loss_sim_sum += loss_sim.cpu().item()\n",
    "        loss_ssim_sum += loss_ssim.cpu().item()\n",
    "        \n",
    "        if(batch_idx+1)%1==0:\n",
    "            print('Train Epoch: %d, loss_sim %.4f, loss_ssim %.4f, time %.1f sec' % (epoch,loss_sim_sum,loss_ssim_sum,time.time()-start))\n",
    "            loss_sim_sum=0\n",
    "            loss_ssim_sum=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15319432-0477-4c1d-a34b-afc370ad63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval1(model,device,trainloader,epoch):\n",
    "    start=time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_sim_sum=0\n",
    "        loss_ssim_sum=0\n",
    "        for batch_idx,(cbct,ct,prior) in enumerate(trainloader):\n",
    "            cbct=cbct.to(device)\n",
    "            ct=ct.to(device)\n",
    "            prior=prior.to(device)\n",
    "            cbct_refine=model(torch.cat([cbct,prior.unsqueeze(2).expand_as(cbct)],dim=1))\n",
    "        \n",
    "            loss_sim=loss_fn(cbct_refine,ct)\n",
    "            loss_ssim=ssim(cbct_refine.squeeze(1)*1000,ct.squeeze(1)*1000)\n",
    "            loss_sim_sum += loss_sim.cpu().item()\n",
    "            loss_ssim_sum += loss_ssim.cpu().item()\n",
    "        print('eval Epoch: %d, loss_sim %.4f, loss_ssim %.4f' % (epoch,loss_sim_sum,loss_ssim_sum/(batch_idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8182e5-016b-4fd6-90c9-db876037177b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lrate=0.00015\n",
    "optimizer=torch.optim.Adam(params,lr=lrate,betas=(0.9, 0.999))\n",
    "for epoch in range(1,61):\n",
    "    train1(model,DEVICE,simuloader,optimizer,epoch)\n",
    "    #torch.save(model.state_dict(),'checkpoints/checkpoints_Tetris1/model_%s.pth'%(epoch))\n",
    "    if (epoch==20 or epoch==30 or epoch==40):\n",
    "        lrate=lrate*0.5\n",
    "        for params in optimizer.param_groups:             \n",
    "            params['lr'] = lrate \n",
    "    eval1(model,DEVICE,evalloader,epoch)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc36a1-2d67-45cd-bcb8-4a3cccd53573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15989352-190e-4a74-aee9-a22e35778f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e7fc1-233a-49f1-ab3b-ac9a2e05aa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54679286-708a-4dfc-8091-b728ea8ac28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225194d-119e-4590-abba-fc96c0ceabfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d1be1-e144-41c5-9df1-e26e31a603e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2d2a8-cf35-41ee-935f-e6e008215d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664cd23-313e-4045-a438-ac3366b2993c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea1871-74fa-4a37-98a5-adc25b3f8707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7a589-6d32-4451-a552-6b6d4043de23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18643b3e-71de-4886-be87-05879524449f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc5584-ec26-4a0f-bc6a-eca80af5b42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2cad21-b222-4b03-b604-7280dd20437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584aa99-b4b5-473c-a642-ff7165f992cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1c171-d276-4ef3-ab31-7de94eb7ba08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3452edd-d486-47d5-9d46-d03359a1cd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899f7d9-9d7c-4fec-8fff-370df74af361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eedaac-d308-403b-a3b4-e59749423237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9e8ac-5f0d-4998-bd85-d5dd8ea7b4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a742bba-7df8-4a0e-8f09-01e1bd4693d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13415f3-3144-4af3-887d-5e6c9375dfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470bc4f7-279e-406e-9e15-c19ff921833d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7753feb-0316-41db-b208-8911b9cd07c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510cc89-0cfd-40e0-9f88-265a50ac09cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecebb1f-9639-43e4-a54e-f2a5ec05bc22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dcf288-51bd-4ea0-885c-b5c5ce3a156a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d93723-0fa5-4cf9-8af1-a923f22c1fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
